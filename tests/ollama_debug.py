from langchain_ollama import OllamaLLM

print("üß† Testing LangChain ‚Üî Ollama (modern API)...")

try:
    llm = OllamaLLM(model="llama3", temperature=0.2)
    response = llm.invoke("Explain what artificial intelligence is.")
    print("‚úÖ Model responded successfully:")
    print(response)
except Exception as e:
    print("‚ùå Error communicating with Ollama:")
    print(e)
